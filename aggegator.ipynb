{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter product name \n",
      "laptop\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-be863da6a281>\u001b[0m in \u001b[0;36mflpc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mname2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'_3wU53n'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mnames2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-be863da6a281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m##comp2.append(names2[prices2.index(min(prices2))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m \u001b[0mflpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-be863da6a281>\u001b[0m in \u001b[0;36mflpc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mname3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'_2cLu-l'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mnames2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mprice3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'_1vC4OE'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "#import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "#import re\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(\"/Users/Anil/chromedriver\")\n",
    "\n",
    "prices1=[] #List to store price of the product\n",
    "prices2=[] #List to store price of the product\n",
    "names1=[]\n",
    "names2=[]\n",
    "c=[]\n",
    "links1=[]\n",
    "links2=[]\n",
    "\n",
    "\n",
    "name = input(\"enter product name \\n\")\n",
    "sites = ['flipkart','amazon']\n",
    "fin=[]\n",
    "comp=[]\n",
    "comp2=[]\n",
    "comp3=[]\n",
    "cntr=0\n",
    "nc = name.strip().replace(' ','+')\n",
    "#&s=price-asc-rank\n",
    "#&sort=price_asc\n",
    "webs=[\"https://www.amazon.in/s?k=NAME&ref=nb_sb_noss\",\"https://www.flipkart.com/search?q=NAME&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"]\n",
    "for i in webs:   \n",
    "    fin.append(i.replace(\"NAME\",nc))\n",
    "    \n",
    "def amzp():\n",
    "    driver.get(fin[0])\n",
    "\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for div in soup.findAll('a',href=True, attrs={'class':'a-link-normal a-text-normal'}):\n",
    "        name1 = div.find('span')#, attrs={'class':'a-size-medium a-color-base a-text-normal'})\n",
    "        link1 = div.get(\"href\")\n",
    "        names1.append(name1.text)\n",
    "        links1.append(link1)\n",
    "            \n",
    "            \n",
    "    for div in soup.findAll('a',href=True, attrs={'class':'a-size-base a-link-normal s-no-hover a-text-normal'}):\n",
    "        price1 = div.find('span', attrs={'class':'a-price-whole'})\n",
    "        prices1.append(price1.text)\n",
    "        \n",
    "            \n",
    "            \n",
    "    q= min(prices1)\n",
    "    p = prices1.index(q)\n",
    "    comp.append(min(prices1))\n",
    "    comp2.append(names1[p])\n",
    "    comp3.append(links1[p])\n",
    "    \n",
    "    \n",
    "    \n",
    "amzp()\n",
    "\n",
    "fp=[]\n",
    "\n",
    "def flpc():\n",
    "    driver.get(fin[1])\n",
    "\n",
    "    content = driver.page_source\n",
    "    soup = BeautifulSoup(content)\n",
    "    for a in soup.findAll('a',href=True, attrs={'rel':'noopener noreferrer'}):\n",
    "        link2 = a.get(\"href\")\n",
    "        links2.append(link2)\n",
    "        #k = a.text\n",
    "        #if re.search('^Not Deliverable',k): continue\n",
    "        #name2 = re.findall('[a-zA-Z]+',k)\n",
    "        #print(name2)\n",
    "        #names2.append(name2[0])\n",
    "        #price2 = re.findall('^₹[0-9]+?',k)\n",
    "        #print(price2)\n",
    "        #prices2.append(price2[0])\n",
    "        \n",
    "        \n",
    "        #zz = re.findall('^₹.+[0-9]?',k)\n",
    "        #for t in zz:\n",
    "            #fp.append(t[1:])\n",
    "    #print(fp)    \n",
    "        try:\n",
    "            name2 = a.find('a', attrs={'class':'_3wU53n'})\n",
    "            names2.append(name2.text)\n",
    "            \n",
    "        except:\n",
    "            name3 = a.find('div', attrs={'class':'_2cLu-l'})\n",
    "            names2.append(name3.text)\n",
    "        #try:    \n",
    "        price3 = a.find('div', attrs={'class':'_1vC4OE'})\n",
    "        if price3!=None:\n",
    "            prices2.append(int(price3.text.replace(',','')[1:]))\n",
    "        #except:\n",
    "        price2 = a.find('div', attrs={'class':'_1vC4OE _2rQ-NK'})\n",
    "        if price2!=None:\n",
    "            prices2.append(int(price2.text.replace(',','')[1:]))\n",
    "\n",
    "    print(names2)   \n",
    "    print(prices2)\n",
    "    print(len(names2))   \n",
    "    print(len(prices2))\n",
    "    mp2 =min(prices2)                     \n",
    "    comp.append(mp2)\n",
    "    comp2.append(names2[prices2.index(mp2)])\n",
    "    comp3.append(links2[prices2.index(mp2)])\n",
    "\n",
    "   # print(min(prices2))\n",
    "    #print(len(names2))\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #price2 = a.find('div', attrs={'class':'_1vC4OE'})\n",
    "        #name2 = a.find('div', attrs={'class':'_3wU53n'})\n",
    "        #print(a.text)\n",
    "        #if nc in name2.text:\n",
    "        #names2.append(a.text)\n",
    "        #prices2.append(price2.text)\n",
    "    ##comp.append(min(prices2))\n",
    "    ##comp2.append(names2[prices2.index(min(prices2))])\n",
    "    \n",
    "flpc()\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nMinimum on Amazon with price ₹\",comp[0])\n",
    "print(comp2[0],\"\\n\")\n",
    "azl = 'https://www.amazon.in/' + comp3[0]\n",
    "print(azl)\n",
    "\n",
    "print(\"\\nMinimum on Flipkart with price ₹\",comp[1])\n",
    "print(comp2[1],\"\\n\")\n",
    "fpl = 'https://www.flipkart.com/' + comp3[1]\n",
    "print(fpl)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'Prices':comp,'names':comp2}) \n",
    "df.to_csv('prices.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
